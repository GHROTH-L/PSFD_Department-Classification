{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWW6ZJEtFS4aXr6HAgjuui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GHROTH-L/PSFD_Department-Classification-/blob/main/%E6%95%B4%E7%90%86%E5%AD%B8%E7%B3%BB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 科系整理"
      ],
      "metadata": {
        "id": "U8PGU7l7Wd9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##先整理大學的科系與對應"
      ],
      "metadata": {
        "id": "1z4cIHFgWg0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdnnHt1ZTbDi"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# 選擇上傳 Excel 檔案\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 取得檔案名稱\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# 讀取 Excel\n",
        "df = pd.read_excel(file_name)\n",
        "\n",
        "# 顯示前幾筆資料\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_data = []\n",
        "for index, row in df.iterrows():\n",
        "    if pd.notna(row[\"discrib\"]):  # 確保第五欄有值\n",
        "        split_values = row[\"discrib\"].split(\"、\")  # 依據頓號切割\n",
        "        for value in split_values:\n",
        "            expanded_data.append([row[\"mainid\"], row[\"midid\"], row[\"lastid\"], value, row[\"eduid\"]])  # 重新組合成新行\n",
        "    else:\n",
        "        expanded_data.append([row[\"mainid\"], row[\"midid\"], row[\"lastid\"], row[\"lastname\"], row[\"eduid\"]])  # 沒有第五欄的保留原始\n",
        "\n",
        "# 轉換為新的 DataFrame\n",
        "expanded_df = pd.DataFrame(expanded_data, columns=[\"mainid\", \"midid\", \"lastid\t\", \"lastname\", \"eduid\"])"
      ],
      "metadata": {
        "id": "zS_BWx3wT3Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_df.head(10)"
      ],
      "metadata": {
        "id": "p1y9WbIyUyus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 假設 df 是你的 DataFrame\n",
        "output_file = \"output.xlsx\"  # 輸出的檔案名稱\n",
        "\n",
        "# 將 DataFrame 儲存為 Excel\n",
        "expanded_df.to_excel(output_file, index=False)\n",
        "\n",
        "# 讓 Colab 下載 Excel 檔案\n",
        "from google.colab import files\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OybaBP02Uzym",
        "outputId": "5c53bb18-3d3c-4f35-c457-ffa00a15474e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a9064579-e221-407a-becd-d9f58444cb96\", \"output.xlsx\", 72398)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ckip 與 jeiba"
      ],
      "metadata": {
        "id": "oAlTfqCZWcHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "! pip install -U ckip-transformers\n",
        "from ckip_transformers import __version__\n",
        "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger, CkipNerChunker\n",
        "from google.colab import files\n",
        "import jieba"
      ],
      "metadata": {
        "id": "GYVPyzTisKyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 文本預處理，這裡可以使用 jieba 進行中文分詞\n",
        "def jieba_text(text):\n",
        "    # 使用 jieba 分詞\n",
        "    words = jieba.cut(text)\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "-S1eXG9bsW6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show version\n",
        "print(__version__)\n",
        "\n",
        "# Initialize drivers\n",
        "print(\"Initializing drivers ... WS\")\n",
        "ws_driver = CkipWordSegmenter(model=\"albert-base\", device=-1)\n",
        "print(\"Initializing drivers ... POS\")\n",
        "pos_driver = CkipPosTagger(model=\"albert-base\", device=-1)\n",
        "print(\"Initializing drivers ... NER\")\n",
        "ner_driver = CkipNerChunker(model=\"albert-base\", device=-1)\n",
        "print(\"Initializing drivers ... all done\")\n",
        "print()\n",
        "\n",
        "#model 有其它的可以選，如 \"bert-base\"\n",
        "#device=0 是使用 GPU， device=-1 是使用 CPU，不指定也可以。\n",
        "def clean(sentence_ws, sentence_pos):\n",
        "  short_with_pos = []\n",
        "  short_sentence = []\n",
        "  stop_pos = set(['Nep', 'Nh', 'Nb',]) # 這 3 種詞性不保留\n",
        "  for word_ws, word_pos in zip(sentence_ws, sentence_pos):\n",
        "    # 只留名詞和動詞\n",
        "    is_N_or_V = word_pos.startswith(\"V\") or word_pos.startswith(\"N\")\n",
        "    # 去掉名詞裡的某些詞性\n",
        "    is_not_stop_pos = word_pos not in stop_pos\n",
        "    # 只剩一個字的詞也不留\n",
        "    is_not_one_charactor = not (len(word_ws) == 1)\n",
        "    # 組成串列\n",
        "    if is_N_or_V and is_not_stop_pos and is_not_one_charactor:\n",
        "      short_with_pos.append(f\"{word_ws}({word_pos})\")\n",
        "      short_sentence.append(f\"{word_ws}\")\n",
        "  return (\" \".join(short_sentence), \" \".join(short_with_pos))\n"
      ],
      "metadata": {
        "id": "u3MvCcmHsY5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload() #上傳資料\n",
        "# Get the filename from the uploaded dictionary\n",
        "filename = list(uploaded.keys())[0]\n",
        "data = pd.read_csv(filename)"
      ],
      "metadata": {
        "id": "Vg41fblPsHD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#確認是否有亂碼\n",
        "with open(filename, \"rb\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        try:\n",
        "            line.decode(\"utf-8\")\n",
        "        except UnicodeDecodeError as e:\n",
        "            print(f\"錯誤發生在第 {i+1} 行，錯誤訊息: {e}\")\n",
        "            break\n",
        "print(data.dtypes)\n",
        "print(data.head(10))"
      ],
      "metadata": {
        "id": "qbNr2gIasd8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(subset=['mainid'], inplace=True)\n",
        "data['mainid'] = data['mainid'].astype(int)"
      ],
      "metadata": {
        "id": "9zNdfbXLQBmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 儲存分詞結果與新的句子\n",
        "data[\"result\"] = \"\"\n",
        "data[\"n_lastname\"] = \"\"\n",
        "\n",
        "# 進行每個部份的分析\n",
        "for index, row in data.iterrows():\n",
        "    description = row[\"lastname\"]\n",
        "    # 分詞\n",
        "    ws_result = ws_driver([description])\n",
        "    # 詞性標註\n",
        "    pos_result = pos_driver(ws_result)\n",
        "\n",
        "    # 清洗數據\n",
        "    cleaned_sentence, cleaned_with_pos = clean(ws_result[0], pos_result[0])\n",
        "\n",
        "    # 保存结果\n",
        "    data.at[index, \"result\"] = cleaned_with_pos\n",
        "    data.at[index, \"n_lastname\"] = cleaned_sentence"
      ],
      "metadata": {
        "id": "Pn3RXLPNsi-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['jeiba_lastname'] = data['lastname'].apply(jieba_text)\n",
        "data['n_lastname'] = data['n_lastname'].fillna(data['jeiba_lastname'])\n",
        "'''\n",
        "nan_indices = data[data['n_lastname'].isna()].index\n",
        "print(nan_indices)\n",
        "nan_rows_details = data.loc[[425, 2172]]\n",
        "print(nan_rows_details)\n",
        "\n",
        "不分系 跟基督教學系會被nan\n",
        "\n",
        "'''\n",
        "print(data.head(10))\n"
      ],
      "metadata": {
        "id": "bPF0KlsHvXHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_indices = data[data['n_lastname'].isna()].index\n",
        "print(nan_indices)\n",
        "nan_rows_details = data.loc[[425, 2172]]\n",
        "nan_rows_details"
      ],
      "metadata": {
        "id": "I0kBOB3-2yeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_filename = \"2022科系分類_奕嘉_已經分詞.csv\"\n",
        "data.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "c-46RxgZ20oj",
        "outputId": "4382013f-9ec7-401e-8916-ae735c111d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_33bd243a-33f6-4fb6-ad59-43d800e680e2\", \"2022\\u79d1\\u7cfb\\u5206\\u985e_\\u5955\\u5609_\\u5df2\\u7d93\\u5206\\u8a5e.csv\", 302660)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##分類測試"
      ],
      "metadata": {
        "id": "6bRd98heWct0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 隨機森林"
      ],
      "metadata": {
        "id": "3p4tIEe20euj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import jieba\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from google.colab import files\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n"
      ],
      "metadata": {
        "id": "hXGnYSzp00TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload() #上傳資料\n",
        "# Get the filename from the uploaded dictionary\n",
        "filename = list(uploaded.keys())[0]\n",
        "data = pd.read_csv(filename)"
      ],
      "metadata": {
        "id": "m-HAQnJN0gub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_indices = data[data['n_lastname'].isna()].index\n",
        "print(nan_indices)\n",
        "nan_rows_details = data.loc[[425, 2172]]\n",
        "print(nan_rows_details)\n"
      ],
      "metadata": {
        "id": "6wKcGmec1_a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_rows_details = data.loc[[425, 2172]]\n",
        "print(nan_rows_details)"
      ],
      "metadata": {
        "id": "S7u-6cs42cUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徵向量化，使用 Tfidf 向量化\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(data['n_lastname'])\n",
        "\n",
        "# 職業編號當作目標變量\n",
        "y = data['mainid']\n",
        "\n",
        "# 分割數據為訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "# 訓練模型\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 預測和評估\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "t__KtJeB0jC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#準確率不高，所以採用smote 後再進行\n",
        "\n",
        "# 檢查類別分部\n",
        "data_df = pd.DataFrame({'lastname': data['n_lastname'], 'label': data['mainid']})\n",
        "label_counts = data_df['label'].value_counts()\n",
        "\n",
        "# 查看是否有少於5筆的樣本\n",
        "rare_labels = label_counts[label_counts < 6].index\n",
        "print(f\"稀有類別: {rare_labels}\")\n"
      ],
      "metadata": {
        "id": "Kk6y50kB6J27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 處理不均衡數據 (使用 SMOTE)\n",
        "X = data_df['lastname'].tolist()\n",
        "y = data_df['label'].tolist()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# 將文本數據轉換為數值特徵\n",
        "vectorizer = TfidfVectorizer(max_features=2500, min_df=1, max_df=0.9)  # 取前 2000 個高頻詞\n",
        "X_vectorized = vectorizer.fit_transform(X)\n",
        "\n",
        "\n",
        "# 使用 SMOTE 平衡類別分佈\n",
        "smote = SMOTE(sampling_strategy='not minority', random_state=42, k_neighbors=5) #複製not minority\n",
        "X_resampled, y_resampled = smote.fit_resample(X_vectorized, y_encoded)\n",
        "\n",
        "# 分割數據集\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=69, stratify=y_resampled\n",
        ")"
      ],
      "metadata": {
        "id": "HYPAPIRe7Vyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練模型：這裡用訓練特徵和訓練標籤\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(train_texts, train_labels)\n",
        "\n",
        "# 預測和評估：用驗證特徵進行預測，並將預測結果與驗證標籤比較\n",
        "y_pred = model.predict(val_texts)\n",
        "print(classification_report(val_labels, y_pred))"
      ],
      "metadata": {
        "id": "4gGDDKkN8pp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 對答案\n"
      ],
      "metadata": {
        "id": "xr7ck-Ekmrzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload() #上傳資料\n",
        "# Get the filename from the uploaded dictionary\n",
        "filename = list(uploaded.keys())[0]\n",
        "data2 = pd.read_csv(filename)"
      ],
      "metadata": {
        "id": "DqoQ1RBrmuc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_evaluate(new_data, model):\n",
        "    # 取得預測結果，注意這裡假設模型接受 ln_lastname 欄位作為輸入\n",
        "    # 將文本數據轉換為數值特徵\n",
        "    X_new = vectorizer.transform(new_data['n_lastname'])\n",
        "\n",
        "    predicted_ids = model.predict(X_new)\n",
        "\n",
        "    # 使用相同的 label_encoder 將編碼數字轉回原始標籤\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_ids)\n",
        "\n",
        "    # 將預測結果加入 DataFrame 中\n",
        "    new_data['predicted_label'] = predicted_labels\n",
        "\n",
        "    # 根據預測結果與原始 mainid 進行比較，產生 code 欄位 (1 表示預測正確，0 表示錯誤)\n",
        "    new_data['code'] = (new_data['predicted_label'] == new_data['mainid']).astype(int)\n",
        "\n",
        "    # 計算準確率\n",
        "    accuracy = new_data['code'].mean()\n",
        "    print(\"準確率：\", accuracy)\n",
        "    return new_data, accuracy"
      ],
      "metadata": {
        "id": "2asFTPRoZJsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2, acc = predict_and_evaluate(data, model)"
      ],
      "metadata": {
        "id": "9uS9A0HalBN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#輸出結果\n",
        "output_filename = \"預測結果比對.csv\"\n",
        "data2.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QCpl1jR4oK5j",
        "outputId": "071b770c-daa1-422f-9f47-b8f57f4b743c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0367cbcf-7908-400b-90b1-63f8f5ce75dc\", \"\\u9810\\u6e2c\\u7d50\\u679c\\u6bd4\\u5c0d.csv\", 317701)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###儲存模型"
      ],
      "metadata": {
        "id": "bJlzzE_vtvXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "# 儲存模型\n",
        "joblib.dump(model, 'model.joblib')\n",
        "joblib.dump(vectorizer, 'vectorizer.joblib')\n",
        "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
        "\n",
        "# 下載模型檔案到本地\n",
        "files.download('model.joblib')\n",
        "files.download('vectorizer.joblib')\n",
        "files.download('label_encoder.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gq15jguWlIuP",
        "outputId": "a8d2a133-1e43-4ab1-c3fd-fda8ca6a7fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fba5d3b9-8f6d-4fd4-ba56-66254058ecff\", \"model.joblib\", 480756649)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e8d09aab-24b4-4c94-bd8b-a418f9173ff6\", \"vectorizer.joblib\", 33543)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e91a4226-4dea-4c39-a600-72bb6a633e95\", \"label_encoder.joblib\", 471)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 上傳模型進行使用"
      ],
      "metadata": {
        "id": "lwj-6zCivJqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# 載入模型\n",
        "model = joblib.load('model.joblib')\n",
        "\n",
        "# 載入 TF-IDF vectorizer\n",
        "vectorizer = joblib.load('vectorizer.joblib')\n",
        "\n",
        "# 載入 LabelEncoder\n",
        "label_encoder = joblib.load('label_encoder.joblib')"
      ],
      "metadata": {
        "id": "O4AiCTBzvfnq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}