{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlAz4ANcbILWX7SiqWkhDK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e0d2a0eef604c9e8b3b90f53110aeb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71ae86a543d04e7984d9b0aeca4ea544",
              "IPY_MODEL_cf97efec8c174cf6bdf8a77dc467b107",
              "IPY_MODEL_3e3b95488f1f4fe69752278203b1b04c"
            ],
            "layout": "IPY_MODEL_dc77e0fbaf60419ab7c2adb95f9e0868"
          }
        },
        "71ae86a543d04e7984d9b0aeca4ea544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e30f4d8e418b4f698d900c7f0f8ac185",
            "placeholder": "​",
            "style": "IPY_MODEL_94810e745080452fa5f7b8abcfd1fa57",
            "value": "config.json: 100%"
          }
        },
        "cf97efec8c174cf6bdf8a77dc467b107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a3131572c644b19c2ef6637bd59e2f",
            "max": 853,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_337a46b48bc241c09edaedd929f4ff5f",
            "value": 853
          }
        },
        "3e3b95488f1f4fe69752278203b1b04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfd2a69e52b34032acafaeaad4bf12db",
            "placeholder": "​",
            "style": "IPY_MODEL_80e970f3bbe442acba928520c88dca15",
            "value": " 853/853 [00:00&lt;00:00, 49.4kB/s]"
          }
        },
        "dc77e0fbaf60419ab7c2adb95f9e0868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30f4d8e418b4f698d900c7f0f8ac185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94810e745080452fa5f7b8abcfd1fa57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09a3131572c644b19c2ef6637bd59e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337a46b48bc241c09edaedd929f4ff5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfd2a69e52b34032acafaeaad4bf12db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80e970f3bbe442acba928520c88dca15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fda7d38cf87947b68c6497d33966d94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cfd0652ee904ca29231cffbe82dda9d",
              "IPY_MODEL_f5e806e6d4704bf39741e4e79a6aaf3f",
              "IPY_MODEL_243a1f6c0bbf4fd5a9219cbf025ee764"
            ],
            "layout": "IPY_MODEL_bbd5e39c790741aeb7e441480a16f1e5"
          }
        },
        "8cfd0652ee904ca29231cffbe82dda9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02284bea53a04525bd77853ef7d4a7aa",
            "placeholder": "​",
            "style": "IPY_MODEL_1eb5c198f7744b81b6c234df50c71185",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "f5e806e6d4704bf39741e4e79a6aaf3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79895f4edfa948cdbf9a9ff5bfad5c98",
            "max": 39851033,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74b92582cc594bcc90ab5339804d6a0a",
            "value": 39851033
          }
        },
        "243a1f6c0bbf4fd5a9219cbf025ee764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c6caaf981ea4164bed43e9d658bea73",
            "placeholder": "​",
            "style": "IPY_MODEL_716e25419c664944a561714ffa47ab33",
            "value": " 39.9M/39.9M [00:00&lt;00:00, 84.8MB/s]"
          }
        },
        "bbd5e39c790741aeb7e441480a16f1e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02284bea53a04525bd77853ef7d4a7aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eb5c198f7744b81b6c234df50c71185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79895f4edfa948cdbf9a9ff5bfad5c98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b92582cc594bcc90ab5339804d6a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c6caaf981ea4164bed43e9d658bea73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716e25419c664944a561714ffa47ab33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a71551ac04443b08fcd5836cfb21da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cb01ef321c2459684d7d0e622c468bc",
              "IPY_MODEL_ac0f047c762143f592a2b78e18d0ebd5",
              "IPY_MODEL_2fd84489e2f543919d177a69a9ed4d28"
            ],
            "layout": "IPY_MODEL_8e73008085324e7bb2a04b869fa23670"
          }
        },
        "4cb01ef321c2459684d7d0e622c468bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5c3fe073c1472899259e244a4c4551",
            "placeholder": "​",
            "style": "IPY_MODEL_aa4aac74366444c38875164271245e71",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ac0f047c762143f592a2b78e18d0ebd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f3f197d6ff74d798b97652cf2a0daaf",
            "max": 301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99a92f7fb454488ebc74bec67f101f59",
            "value": 301
          }
        },
        "2fd84489e2f543919d177a69a9ed4d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd3774705a34ba9821b4efd52edb39d",
            "placeholder": "​",
            "style": "IPY_MODEL_a0dc295542264fc081bc690e44f975a1",
            "value": " 301/301 [00:00&lt;00:00, 13.1kB/s]"
          }
        },
        "8e73008085324e7bb2a04b869fa23670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5c3fe073c1472899259e244a4c4551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa4aac74366444c38875164271245e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f3f197d6ff74d798b97652cf2a0daaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99a92f7fb454488ebc74bec67f101f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fd3774705a34ba9821b4efd52edb39d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0dc295542264fc081bc690e44f975a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6bc701fd35b418db36217f0eb97dc60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cec8287f0d8a4b66bfea9ace61dcd768",
              "IPY_MODEL_e035a26a5e754bf1b30b8e0fa99b5cb0",
              "IPY_MODEL_73504b40f5444c83b647549966116003"
            ],
            "layout": "IPY_MODEL_dc461224a7904975a6acf0f0474da11b"
          }
        },
        "cec8287f0d8a4b66bfea9ace61dcd768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b5dc2e664a414a83ed5902cc1d220a",
            "placeholder": "​",
            "style": "IPY_MODEL_5294c2bd94184e04b8a024ae1d76a97c",
            "value": "vocab.txt: 100%"
          }
        },
        "e035a26a5e754bf1b30b8e0fa99b5cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0ced96f33f243f2a5c0129147999480",
            "max": 109540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dedc6d2784374c25b0a942fb5244f186",
            "value": 109540
          }
        },
        "73504b40f5444c83b647549966116003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a8e2e3c1744e7f8154d4c8f7170581",
            "placeholder": "​",
            "style": "IPY_MODEL_fa3a5dd0532641269c36326ba26aed72",
            "value": " 110k/110k [00:00&lt;00:00, 3.39MB/s]"
          }
        },
        "dc461224a7904975a6acf0f0474da11b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b5dc2e664a414a83ed5902cc1d220a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5294c2bd94184e04b8a024ae1d76a97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0ced96f33f243f2a5c0129147999480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dedc6d2784374c25b0a942fb5244f186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1a8e2e3c1744e7f8154d4c8f7170581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa3a5dd0532641269c36326ba26aed72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af1caa9e460f46dfac53678a4d8f6942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1df324199604c799f80c0b496db1a54",
              "IPY_MODEL_f9d84de4e06646a1ace683bc48e94d66",
              "IPY_MODEL_e53cbd65b8354c868c9c0e7e17513703"
            ],
            "layout": "IPY_MODEL_a256aef7bf414c01bcb614044182fbf0"
          }
        },
        "e1df324199604c799f80c0b496db1a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3d7a2637bec4b4fa5fc8283efb9b493",
            "placeholder": "​",
            "style": "IPY_MODEL_f06a4ab2b75b40cf9a7e339e19aa4065",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f9d84de4e06646a1ace683bc48e94d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68c684d5c35546a2ad417ea8f66a60b8",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32c2a8b301af450a94ba3edb0ca6db64",
            "value": 112
          }
        },
        "e53cbd65b8354c868c9c0e7e17513703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f35001c1aa94bd58af656bb92e7ed4a",
            "placeholder": "​",
            "style": "IPY_MODEL_409f5d8f8dd24825b579323aabf33b3e",
            "value": " 112/112 [00:00&lt;00:00, 7.83kB/s]"
          }
        },
        "a256aef7bf414c01bcb614044182fbf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3d7a2637bec4b4fa5fc8283efb9b493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f06a4ab2b75b40cf9a7e339e19aa4065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68c684d5c35546a2ad417ea8f66a60b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32c2a8b301af450a94ba3edb0ca6db64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f35001c1aa94bd58af656bb92e7ed4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409f5d8f8dd24825b579323aabf33b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc129c35956b440d82684fe311fc9860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8508c4a75d054ad68e0e3b9b2e3f8f52",
              "IPY_MODEL_2bc9d708e82d470d992a4f3972721a45",
              "IPY_MODEL_e090bd85842743729aa0bc114d5046cd"
            ],
            "layout": "IPY_MODEL_41bfc27e5b9b41c38aada8b8fe82751e"
          }
        },
        "8508c4a75d054ad68e0e3b9b2e3f8f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8c5204283d34b2594cd00514043df0c",
            "placeholder": "​",
            "style": "IPY_MODEL_b2412d0d02fa469f9cbf6342ddecbd5e",
            "value": "config.json: 100%"
          }
        },
        "2bc9d708e82d470d992a4f3972721a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4b4ecc5e7784fb8a24b6c958b66d77b",
            "max": 2909,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a111f124427540e393cb0e8993cc6718",
            "value": 2909
          }
        },
        "e090bd85842743729aa0bc114d5046cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d232ea67c3b74ddb8f0900af58bd1c9a",
            "placeholder": "​",
            "style": "IPY_MODEL_22faf84773af42a6b0ef0c670c81f0ac",
            "value": " 2.91k/2.91k [00:00&lt;00:00, 116kB/s]"
          }
        },
        "41bfc27e5b9b41c38aada8b8fe82751e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8c5204283d34b2594cd00514043df0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2412d0d02fa469f9cbf6342ddecbd5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4b4ecc5e7784fb8a24b6c958b66d77b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a111f124427540e393cb0e8993cc6718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d232ea67c3b74ddb8f0900af58bd1c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22faf84773af42a6b0ef0c670c81f0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "262ed90f2f1f414b9363ca67fce55260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aba2ca727aef49e3bdd723f16283a385",
              "IPY_MODEL_718dbab97cea43159953fea89c2bdec4",
              "IPY_MODEL_189b05bd350f451fba6cd9e5ce466441"
            ],
            "layout": "IPY_MODEL_fd84e5f9ad964889ad288a1442619ddf"
          }
        },
        "aba2ca727aef49e3bdd723f16283a385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_305c19f6a2774e1dbd3ac1e3037eab97",
            "placeholder": "​",
            "style": "IPY_MODEL_377efbd7f8c44b6cad894bfe081e88b2",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "718dbab97cea43159953fea89c2bdec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27126925327e4dd2b991d46fb10f5e4c",
            "max": 40029401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_558d12556cac4aab857eeb4e29fdcb3e",
            "value": 40029401
          }
        },
        "189b05bd350f451fba6cd9e5ce466441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8736ca4c92634106a7d1f442af1695f4",
            "placeholder": "​",
            "style": "IPY_MODEL_a956d3abbba24cc7a98159f2e0b60258",
            "value": " 40.0M/40.0M [00:00&lt;00:00, 132MB/s]"
          }
        },
        "fd84e5f9ad964889ad288a1442619ddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305c19f6a2774e1dbd3ac1e3037eab97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "377efbd7f8c44b6cad894bfe081e88b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27126925327e4dd2b991d46fb10f5e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558d12556cac4aab857eeb4e29fdcb3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8736ca4c92634106a7d1f442af1695f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a956d3abbba24cc7a98159f2e0b60258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffb7451b161c4a3eb72b6d7085e5b4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2db692db52214a4faaf5bd63b13bb3ea",
              "IPY_MODEL_82bc43595018467fac54024835a7ef3d",
              "IPY_MODEL_381086936ffd4d41bfb636f03d271ec0"
            ],
            "layout": "IPY_MODEL_dd914a15b804496a828daf3c900f74c7"
          }
        },
        "2db692db52214a4faaf5bd63b13bb3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bd017ef336f4268ba3d1aa77c2fb24d",
            "placeholder": "​",
            "style": "IPY_MODEL_b92a6d373dca4d74a27a0c00f7d2cacf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "82bc43595018467fac54024835a7ef3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44b7ea1ac329448ea4566642c0ea7fc9",
            "max": 301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7291f65a2a04e55991414007e103c74",
            "value": 301
          }
        },
        "381086936ffd4d41bfb636f03d271ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e3e2e68d6fe430cadbc858013d7f988",
            "placeholder": "​",
            "style": "IPY_MODEL_166a42624c6e4ce792f1262ef2ed75f0",
            "value": " 301/301 [00:00&lt;00:00, 8.41kB/s]"
          }
        },
        "dd914a15b804496a828daf3c900f74c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd017ef336f4268ba3d1aa77c2fb24d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b92a6d373dca4d74a27a0c00f7d2cacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44b7ea1ac329448ea4566642c0ea7fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7291f65a2a04e55991414007e103c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e3e2e68d6fe430cadbc858013d7f988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "166a42624c6e4ce792f1262ef2ed75f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b91452374c384076943cb89d62789d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7381d72c7de24c32a4b3d144f3bb0fcf",
              "IPY_MODEL_5d32e74bfe5244f9bca392b05beab73e",
              "IPY_MODEL_ebd3497363204f3a891bf5dab4cab7a8"
            ],
            "layout": "IPY_MODEL_d2ca90af16e2420288d92fb27272d772"
          }
        },
        "7381d72c7de24c32a4b3d144f3bb0fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc795cf1fc32405a8e249ad72c687303",
            "placeholder": "​",
            "style": "IPY_MODEL_9207616c27494f839a354b1ba16fbd43",
            "value": "vocab.txt: 100%"
          }
        },
        "5d32e74bfe5244f9bca392b05beab73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51abbf45f89b4775b8f4830faa240d81",
            "max": 109540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d9f6285b5454cf1bcea21e7dc99525e",
            "value": 109540
          }
        },
        "ebd3497363204f3a891bf5dab4cab7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63d2c8fcb4944e16b433af83eb9f7e40",
            "placeholder": "​",
            "style": "IPY_MODEL_a623a90da83d4bb9adf189446a63c5ae",
            "value": " 110k/110k [00:00&lt;00:00, 5.35MB/s]"
          }
        },
        "d2ca90af16e2420288d92fb27272d772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc795cf1fc32405a8e249ad72c687303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9207616c27494f839a354b1ba16fbd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51abbf45f89b4775b8f4830faa240d81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d9f6285b5454cf1bcea21e7dc99525e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63d2c8fcb4944e16b433af83eb9f7e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a623a90da83d4bb9adf189446a63c5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28c71bb15a41456b89e08e85cdf78bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e4fa9b1d6c24bd699f4e1af15781aa3",
              "IPY_MODEL_00f34782ddd8496b9a8992e534dedac7",
              "IPY_MODEL_bcbaa7d759014719912791ddef15c3c2"
            ],
            "layout": "IPY_MODEL_7721fc4529164782b1a10406a899c178"
          }
        },
        "2e4fa9b1d6c24bd699f4e1af15781aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390ed45884b9478d829ab98fb5b5a1e5",
            "placeholder": "​",
            "style": "IPY_MODEL_b81df7e67a044e9b89fc2f962aeb471f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "00f34782ddd8496b9a8992e534dedac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac980bbeabfb42f9b167ae6f6841d8e3",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bce3290bf98f4252b77e9ade697cbce4",
            "value": 112
          }
        },
        "bcbaa7d759014719912791ddef15c3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_693c99d508e04f7787fe1c832f1cfc00",
            "placeholder": "​",
            "style": "IPY_MODEL_af4125056ef04fce967a747368e17f0a",
            "value": " 112/112 [00:00&lt;00:00, 1.93kB/s]"
          }
        },
        "7721fc4529164782b1a10406a899c178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390ed45884b9478d829ab98fb5b5a1e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b81df7e67a044e9b89fc2f962aeb471f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac980bbeabfb42f9b167ae6f6841d8e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce3290bf98f4252b77e9ade697cbce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "693c99d508e04f7787fe1c832f1cfc00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4125056ef04fce967a747368e17f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4a9692e84344b7fbb0980b89723a4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e54809a18c64b6eb50b0b4628db42aa",
              "IPY_MODEL_853973605bae4ec4b84c63497490c8b3",
              "IPY_MODEL_d8a56f7a5162498d9927d3668482b67b"
            ],
            "layout": "IPY_MODEL_bbb539bfbad7443a9438010f684b5b10"
          }
        },
        "0e54809a18c64b6eb50b0b4628db42aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1762083d5e704eac8c65d0f0528c521e",
            "placeholder": "​",
            "style": "IPY_MODEL_251100edbafd41ab955d8f620e3fcde5",
            "value": "config.json: 100%"
          }
        },
        "853973605bae4ec4b84c63497490c8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85b07122eba41c9adbf7f33ed15beef",
            "max": 3761,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ed994e468c941debd9864228a27ddb8",
            "value": 3761
          }
        },
        "d8a56f7a5162498d9927d3668482b67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2142f066509457d80c0fd851daa1e54",
            "placeholder": "​",
            "style": "IPY_MODEL_7ccdd7a85645462c953ef41de0f7ac56",
            "value": " 3.76k/3.76k [00:00&lt;00:00, 222kB/s]"
          }
        },
        "bbb539bfbad7443a9438010f684b5b10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1762083d5e704eac8c65d0f0528c521e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251100edbafd41ab955d8f620e3fcde5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d85b07122eba41c9adbf7f33ed15beef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed994e468c941debd9864228a27ddb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2142f066509457d80c0fd851daa1e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ccdd7a85645462c953ef41de0f7ac56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9a10bf9695e4cf798c55efc480bc447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41cd94f4ab09476bb6c16b8fdb14f399",
              "IPY_MODEL_76c43c78d9a54518937b7b92a164d8b8",
              "IPY_MODEL_744a3f4648ee4acaaff729af93e2f86e"
            ],
            "layout": "IPY_MODEL_4d260760b69f4a4f97173169fe505c67"
          }
        },
        "41cd94f4ab09476bb6c16b8fdb14f399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8871f76faf9f442b8730b260bce4dbd1",
            "placeholder": "​",
            "style": "IPY_MODEL_34a0d90d197a49b4881821cf30968d60",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "76c43c78d9a54518937b7b92a164d8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65c0ffe932ca4f25899f52eeb897be70",
            "max": 40069401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17609ecfa19d43ecb4e51536ee169c39",
            "value": 40069401
          }
        },
        "744a3f4648ee4acaaff729af93e2f86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc94ff6990a14597aefdf0b17c703647",
            "placeholder": "​",
            "style": "IPY_MODEL_d7e6e744bb884e81876a39ac8b35b479",
            "value": " 40.1M/40.1M [00:00&lt;00:00, 165MB/s]"
          }
        },
        "4d260760b69f4a4f97173169fe505c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8871f76faf9f442b8730b260bce4dbd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a0d90d197a49b4881821cf30968d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65c0ffe932ca4f25899f52eeb897be70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17609ecfa19d43ecb4e51536ee169c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc94ff6990a14597aefdf0b17c703647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e6e744bb884e81876a39ac8b35b479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c203298342cc4704a60ba687eb3e70c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adaf2117ce294337bd4001145cac89c5",
              "IPY_MODEL_2d9faf9266264e0487b0db3d8f09d09c",
              "IPY_MODEL_3e36bb4f3f954231bb00e69a8240c9cf"
            ],
            "layout": "IPY_MODEL_eed845a350cc4ced810f11b9555cd1ab"
          }
        },
        "adaf2117ce294337bd4001145cac89c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c47e79cc7da84957910738e27f0ee805",
            "placeholder": "​",
            "style": "IPY_MODEL_97a950da39904ddeb2f988360e03ca81",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2d9faf9266264e0487b0db3d8f09d09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc6fa6310a7e46d1b61dc4e88214edec",
            "max": 301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_818117ad1e914abdab03e02e0663fa86",
            "value": 301
          }
        },
        "3e36bb4f3f954231bb00e69a8240c9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d409416f4bf649839501f1c853d30415",
            "placeholder": "​",
            "style": "IPY_MODEL_6cf837dca646422eb5ec44033a1e1dff",
            "value": " 301/301 [00:00&lt;00:00, 15.4kB/s]"
          }
        },
        "eed845a350cc4ced810f11b9555cd1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c47e79cc7da84957910738e27f0ee805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97a950da39904ddeb2f988360e03ca81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc6fa6310a7e46d1b61dc4e88214edec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "818117ad1e914abdab03e02e0663fa86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d409416f4bf649839501f1c853d30415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cf837dca646422eb5ec44033a1e1dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61ad00be04cb4b24bbb183816a72dd0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b0787c5d71c40cc94f9dce240e233f5",
              "IPY_MODEL_1713ba941ddd4f0eb1e0a323cab90dc2",
              "IPY_MODEL_a3d641af2a5d4ffa86d6b1956c91a63a"
            ],
            "layout": "IPY_MODEL_29b617b6f2fd45f0a397f943d4471680"
          }
        },
        "2b0787c5d71c40cc94f9dce240e233f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_821d5215bf3d4bf2b49dbcabfe826b39",
            "placeholder": "​",
            "style": "IPY_MODEL_05320863dbbd4d7980f5f3bd82de5b6b",
            "value": "vocab.txt: 100%"
          }
        },
        "1713ba941ddd4f0eb1e0a323cab90dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90cb57eea72b4b539fb93395039725b6",
            "max": 109540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2a2bc5a46f74671b5cd3d53518555a5",
            "value": 109540
          }
        },
        "a3d641af2a5d4ffa86d6b1956c91a63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aa1ad307ad04f37b3f26e9110617233",
            "placeholder": "​",
            "style": "IPY_MODEL_99c2213da6d9406a8f72db765b45c8bb",
            "value": " 110k/110k [00:00&lt;00:00, 6.11MB/s]"
          }
        },
        "29b617b6f2fd45f0a397f943d4471680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821d5215bf3d4bf2b49dbcabfe826b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05320863dbbd4d7980f5f3bd82de5b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90cb57eea72b4b539fb93395039725b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a2bc5a46f74671b5cd3d53518555a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4aa1ad307ad04f37b3f26e9110617233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99c2213da6d9406a8f72db765b45c8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f31aa1c9b45d42cdad17a35008d83246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97b58072a4b442beb42df64987ed16db",
              "IPY_MODEL_c05dc976797a4cbe82e3c7c982b8f26a",
              "IPY_MODEL_83d229f50e784c21b4a2b4fd7fc9c45a"
            ],
            "layout": "IPY_MODEL_e4a82c5146fb4e469610fd238f490689"
          }
        },
        "97b58072a4b442beb42df64987ed16db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b979d1960d242baa246e4e54580b3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_c2eb113b70bf443280afed3f6bba7c2f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c05dc976797a4cbe82e3c7c982b8f26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0f05ab3e869449b975aa32d34994340",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a5a6811cda2495785f6a0c7f68d9799",
            "value": 112
          }
        },
        "83d229f50e784c21b4a2b4fd7fc9c45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83dab553949c43e4a9dd580d7c63fa37",
            "placeholder": "​",
            "style": "IPY_MODEL_58d0d67787364e1c9f8fbbe70bdc5188",
            "value": " 112/112 [00:00&lt;00:00, 3.46kB/s]"
          }
        },
        "e4a82c5146fb4e469610fd238f490689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b979d1960d242baa246e4e54580b3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2eb113b70bf443280afed3f6bba7c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0f05ab3e869449b975aa32d34994340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5a6811cda2495785f6a0c7f68d9799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83dab553949c43e4a9dd580d7c63fa37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d0d67787364e1c9f8fbbe70bdc5188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GHROTH-L/-PSFD_Department-Classification-/blob/main/%E6%95%B4%E7%90%86%E5%AD%B8%E7%B3%BB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 科系整理"
      ],
      "metadata": {
        "id": "U8PGU7l7Wd9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##先整理大學的科系與對應"
      ],
      "metadata": {
        "id": "1z4cIHFgWg0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "wdnnHt1ZTbDi",
        "outputId": "436496d5-80b2-416c-d4bd-b0269fd9a94b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-07a5006f-ca02-43b2-ac82-0e1f54fb5583\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-07a5006f-ca02-43b2-ac82-0e1f54fb5583\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-1e67ce2baee8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 取得檔案名稱\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 讀取 Excel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# 選擇上傳 Excel 檔案\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 取得檔案名稱\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# 讀取 Excel\n",
        "df = pd.read_excel(file_name)\n",
        "\n",
        "# 顯示前幾筆資料\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_data = []\n",
        "for index, row in df.iterrows():\n",
        "    if pd.notna(row[\"discrib\"]):  # 確保第五欄有值\n",
        "        split_values = row[\"discrib\"].split(\"、\")  # 依據頓號切割\n",
        "        for value in split_values:\n",
        "            expanded_data.append([row[\"mainid\"], row[\"midid\"], row[\"lastid\"], value, row[\"eduid\"]])  # 重新組合成新行\n",
        "    else:\n",
        "        expanded_data.append([row[\"mainid\"], row[\"midid\"], row[\"lastid\"], row[\"lastname\"], row[\"eduid\"]])  # 沒有第五欄的保留原始\n",
        "\n",
        "# 轉換為新的 DataFrame\n",
        "expanded_df = pd.DataFrame(expanded_data, columns=[\"mainid\", \"midid\", \"lastid\t\", \"lastname\", \"eduid\"])"
      ],
      "metadata": {
        "id": "zS_BWx3wT3Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "p1y9WbIyUyus",
        "outputId": "bad42036-c017-4bb5-bb19-a07b6c837f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mainid  midid  lastid\\t   lastname     eduid\n",
              "0       2    201     20101       教育學系  140101.0\n",
              "1       2    201     20102     比較教育學系  140102.0\n",
              "2       2    201     20103     國民教育學系  140103.0\n",
              "3       2    201     20104   多元文化教育學系  140104.0\n",
              "4       2    201     20105   課程與教學研究所  140105.0\n",
              "5       2    201     20105      課程研究所  140105.0\n",
              "6       2    201     20106  教育專業發展研究所  140106.0\n",
              "7       2    201     20107  教育心理與輔導學系  140107.0\n",
              "8       2    201     20107       輔導學系  140107.0\n",
              "9       2    201     20108  教育心理與諮商學系  140108.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18e78a7d-633b-41a6-86e8-c1bfa24a51a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mainid</th>\n",
              "      <th>midid</th>\n",
              "      <th>lastid\\t</th>\n",
              "      <th>lastname</th>\n",
              "      <th>eduid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>20101</td>\n",
              "      <td>教育學系</td>\n",
              "      <td>140101.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>20102</td>\n",
              "      <td>比較教育學系</td>\n",
              "      <td>140102.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>20103</td>\n",
              "      <td>國民教育學系</td>\n",
              "      <td>140103.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>20104</td>\n",
              "      <td>多元文化教育學系</td>\n",
              "      <td>140104.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>20105</td>\n",
              "      <td>課程與教學研究所</td>\n",
              "      <td>140105.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>20105</td>\n",
              "      <td>課程研究所</td>\n",
              "      <td>140105.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>20106</td>\n",
              "      <td>教育專業發展研究所</td>\n",
              "      <td>140106.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>20107</td>\n",
              "      <td>教育心理與輔導學系</td>\n",
              "      <td>140107.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>20107</td>\n",
              "      <td>輔導學系</td>\n",
              "      <td>140107.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "      <td>20108</td>\n",
              "      <td>教育心理與諮商學系</td>\n",
              "      <td>140108.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18e78a7d-633b-41a6-86e8-c1bfa24a51a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18e78a7d-633b-41a6-86e8-c1bfa24a51a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18e78a7d-633b-41a6-86e8-c1bfa24a51a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-55af3d38-b76b-4983-8c40-58028fed8670\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55af3d38-b76b-4983-8c40-58028fed8670')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-55af3d38-b76b-4983-8c40-58028fed8670 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "expanded_df",
              "summary": "{\n  \"name\": \"expanded_df\",\n  \"rows\": 2198,\n  \"fields\": [\n    {\n      \"column\": \"mainid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 2,\n        \"max\": 97,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          2,\n          3,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"midid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 922,\n        \"min\": 201,\n        \"max\": 9703,\n        \"num_unique_values\": 159,\n        \"samples\": [\n          813,\n          9703,\n          1411\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lastid\\t\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 92254,\n        \"min\": 20101,\n        \"max\": 970303,\n        \"num_unique_values\": 1863,\n        \"samples\": [\n          31113,\n          51004,\n          120147\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lastname\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2187,\n        \"samples\": [\n          \"\\u6f01\\u696d\\u79d1\\u5b78\\u7814\\u7a76\\u6240\",\n          \"\\u81e8\\u5e8a\\u7259\\u91ab\\u5b78\\u7814\\u7a76\\u6240\",\n          \"\\u98a8\\u96aa\\u7ba1\\u7406\\u8207\\u7d71\\u8a08\\u8cc7\\u8a0a\\u7814\\u7a76\\u6240\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eduid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 216369.7067567174,\n        \"min\": 140101.0,\n        \"max\": 990199.0,\n        \"num_unique_values\": 1724,\n        \"samples\": [\n          220310.0,\n          529904.0,\n          760308.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 假設 df 是你的 DataFrame\n",
        "output_file = \"output.xlsx\"  # 輸出的檔案名稱\n",
        "\n",
        "# 將 DataFrame 儲存為 Excel\n",
        "expanded_df.to_excel(output_file, index=False)\n",
        "\n",
        "# 讓 Colab 下載 Excel 檔案\n",
        "from google.colab import files\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OybaBP02Uzym",
        "outputId": "5c53bb18-3d3c-4f35-c457-ffa00a15474e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a9064579-e221-407a-becd-d9f58444cb96\", \"output.xlsx\", 72398)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ckip 與 jeiba"
      ],
      "metadata": {
        "id": "oAlTfqCZWcHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "! pip install -U ckip-transformers\n",
        "from ckip_transformers import __version__\n",
        "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger, CkipNerChunker\n",
        "from google.colab import files\n",
        "import jieba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYVPyzTisKyr",
        "outputId": "5fea2225-7749-41e6-bef5-f95850452e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ckip-transformers\n",
            "  Downloading ckip_transformers-0.3.4-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from ckip-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from ckip-transformers) (4.67.1)\n",
            "Requirement already satisfied: transformers>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from ckip-transformers) (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->ckip-transformers) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->ckip-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->ckip-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->ckip-transformers) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->ckip-transformers) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.5.0->ckip-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.5.0->ckip-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.5.0->ckip-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.5.0->ckip-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.5.0->ckip-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.5.0->ckip-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.5.0->ckip-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.5.0->ckip-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.5.0->ckip-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->ckip-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->ckip-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.5.0->ckip-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->ckip-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->ckip-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->ckip-transformers) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.5.0->ckip-transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.5.0->ckip-transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.5.0->ckip-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.5.0->ckip-transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.5.0->ckip-transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=3.5.0->ckip-transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.5.0->ckip-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.5.0->ckip-transformers) (0.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->ckip-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=3.5.0->ckip-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=3.5.0->ckip-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=3.5.0->ckip-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=3.5.0->ckip-transformers) (2024.12.14)\n",
            "Downloading ckip_transformers-0.3.4-py3-none-any.whl (26 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ckip-transformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed ckip-transformers-0.3.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文本預處理，這裡可以使用 jieba 進行中文分詞\n",
        "def jieba_text(text):\n",
        "    # 使用 jieba 分詞\n",
        "    words = jieba.cut(text)\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "-S1eXG9bsW6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show version\n",
        "print(__version__)\n",
        "\n",
        "# Initialize drivers\n",
        "print(\"Initializing drivers ... WS\")\n",
        "ws_driver = CkipWordSegmenter(model=\"albert-base\", device=-1)\n",
        "print(\"Initializing drivers ... POS\")\n",
        "pos_driver = CkipPosTagger(model=\"albert-base\", device=-1)\n",
        "print(\"Initializing drivers ... NER\")\n",
        "ner_driver = CkipNerChunker(model=\"albert-base\", device=-1)\n",
        "print(\"Initializing drivers ... all done\")\n",
        "print()\n",
        "\n",
        "#model 有其它的可以選，如 \"bert-base\"\n",
        "#device=0 是使用 GPU， device=-1 是使用 CPU，不指定也可以。\n",
        "def clean(sentence_ws, sentence_pos):\n",
        "  short_with_pos = []\n",
        "  short_sentence = []\n",
        "  stop_pos = set(['Nep', 'Nh', 'Nb',]) # 這 3 種詞性不保留\n",
        "  for word_ws, word_pos in zip(sentence_ws, sentence_pos):\n",
        "    # 只留名詞和動詞\n",
        "    is_N_or_V = word_pos.startswith(\"V\") or word_pos.startswith(\"N\")\n",
        "    # 去掉名詞裡的某些詞性\n",
        "    is_not_stop_pos = word_pos not in stop_pos\n",
        "    # 只剩一個字的詞也不留\n",
        "    is_not_one_charactor = not (len(word_ws) == 1)\n",
        "    # 組成串列\n",
        "    if is_N_or_V and is_not_stop_pos and is_not_one_charactor:\n",
        "      short_with_pos.append(f\"{word_ws}({word_pos})\")\n",
        "      short_sentence.append(f\"{word_ws}\")\n",
        "  return (\" \".join(short_sentence), \" \".join(short_with_pos))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725,
          "referenced_widgets": [
            "8e0d2a0eef604c9e8b3b90f53110aeb5",
            "71ae86a543d04e7984d9b0aeca4ea544",
            "cf97efec8c174cf6bdf8a77dc467b107",
            "3e3b95488f1f4fe69752278203b1b04c",
            "dc77e0fbaf60419ab7c2adb95f9e0868",
            "e30f4d8e418b4f698d900c7f0f8ac185",
            "94810e745080452fa5f7b8abcfd1fa57",
            "09a3131572c644b19c2ef6637bd59e2f",
            "337a46b48bc241c09edaedd929f4ff5f",
            "dfd2a69e52b34032acafaeaad4bf12db",
            "80e970f3bbe442acba928520c88dca15",
            "fda7d38cf87947b68c6497d33966d94e",
            "8cfd0652ee904ca29231cffbe82dda9d",
            "f5e806e6d4704bf39741e4e79a6aaf3f",
            "243a1f6c0bbf4fd5a9219cbf025ee764",
            "bbd5e39c790741aeb7e441480a16f1e5",
            "02284bea53a04525bd77853ef7d4a7aa",
            "1eb5c198f7744b81b6c234df50c71185",
            "79895f4edfa948cdbf9a9ff5bfad5c98",
            "74b92582cc594bcc90ab5339804d6a0a",
            "9c6caaf981ea4164bed43e9d658bea73",
            "716e25419c664944a561714ffa47ab33",
            "7a71551ac04443b08fcd5836cfb21da5",
            "4cb01ef321c2459684d7d0e622c468bc",
            "ac0f047c762143f592a2b78e18d0ebd5",
            "2fd84489e2f543919d177a69a9ed4d28",
            "8e73008085324e7bb2a04b869fa23670",
            "9f5c3fe073c1472899259e244a4c4551",
            "aa4aac74366444c38875164271245e71",
            "7f3f197d6ff74d798b97652cf2a0daaf",
            "99a92f7fb454488ebc74bec67f101f59",
            "4fd3774705a34ba9821b4efd52edb39d",
            "a0dc295542264fc081bc690e44f975a1",
            "f6bc701fd35b418db36217f0eb97dc60",
            "cec8287f0d8a4b66bfea9ace61dcd768",
            "e035a26a5e754bf1b30b8e0fa99b5cb0",
            "73504b40f5444c83b647549966116003",
            "dc461224a7904975a6acf0f0474da11b",
            "67b5dc2e664a414a83ed5902cc1d220a",
            "5294c2bd94184e04b8a024ae1d76a97c",
            "b0ced96f33f243f2a5c0129147999480",
            "dedc6d2784374c25b0a942fb5244f186",
            "e1a8e2e3c1744e7f8154d4c8f7170581",
            "fa3a5dd0532641269c36326ba26aed72",
            "af1caa9e460f46dfac53678a4d8f6942",
            "e1df324199604c799f80c0b496db1a54",
            "f9d84de4e06646a1ace683bc48e94d66",
            "e53cbd65b8354c868c9c0e7e17513703",
            "a256aef7bf414c01bcb614044182fbf0",
            "d3d7a2637bec4b4fa5fc8283efb9b493",
            "f06a4ab2b75b40cf9a7e339e19aa4065",
            "68c684d5c35546a2ad417ea8f66a60b8",
            "32c2a8b301af450a94ba3edb0ca6db64",
            "0f35001c1aa94bd58af656bb92e7ed4a",
            "409f5d8f8dd24825b579323aabf33b3e",
            "dc129c35956b440d82684fe311fc9860",
            "8508c4a75d054ad68e0e3b9b2e3f8f52",
            "2bc9d708e82d470d992a4f3972721a45",
            "e090bd85842743729aa0bc114d5046cd",
            "41bfc27e5b9b41c38aada8b8fe82751e",
            "b8c5204283d34b2594cd00514043df0c",
            "b2412d0d02fa469f9cbf6342ddecbd5e",
            "a4b4ecc5e7784fb8a24b6c958b66d77b",
            "a111f124427540e393cb0e8993cc6718",
            "d232ea67c3b74ddb8f0900af58bd1c9a",
            "22faf84773af42a6b0ef0c670c81f0ac",
            "262ed90f2f1f414b9363ca67fce55260",
            "aba2ca727aef49e3bdd723f16283a385",
            "718dbab97cea43159953fea89c2bdec4",
            "189b05bd350f451fba6cd9e5ce466441",
            "fd84e5f9ad964889ad288a1442619ddf",
            "305c19f6a2774e1dbd3ac1e3037eab97",
            "377efbd7f8c44b6cad894bfe081e88b2",
            "27126925327e4dd2b991d46fb10f5e4c",
            "558d12556cac4aab857eeb4e29fdcb3e",
            "8736ca4c92634106a7d1f442af1695f4",
            "a956d3abbba24cc7a98159f2e0b60258",
            "ffb7451b161c4a3eb72b6d7085e5b4e8",
            "2db692db52214a4faaf5bd63b13bb3ea",
            "82bc43595018467fac54024835a7ef3d",
            "381086936ffd4d41bfb636f03d271ec0",
            "dd914a15b804496a828daf3c900f74c7",
            "7bd017ef336f4268ba3d1aa77c2fb24d",
            "b92a6d373dca4d74a27a0c00f7d2cacf",
            "44b7ea1ac329448ea4566642c0ea7fc9",
            "e7291f65a2a04e55991414007e103c74",
            "9e3e2e68d6fe430cadbc858013d7f988",
            "166a42624c6e4ce792f1262ef2ed75f0",
            "b91452374c384076943cb89d62789d15",
            "7381d72c7de24c32a4b3d144f3bb0fcf",
            "5d32e74bfe5244f9bca392b05beab73e",
            "ebd3497363204f3a891bf5dab4cab7a8",
            "d2ca90af16e2420288d92fb27272d772",
            "bc795cf1fc32405a8e249ad72c687303",
            "9207616c27494f839a354b1ba16fbd43",
            "51abbf45f89b4775b8f4830faa240d81",
            "7d9f6285b5454cf1bcea21e7dc99525e",
            "63d2c8fcb4944e16b433af83eb9f7e40",
            "a623a90da83d4bb9adf189446a63c5ae",
            "28c71bb15a41456b89e08e85cdf78bfb",
            "2e4fa9b1d6c24bd699f4e1af15781aa3",
            "00f34782ddd8496b9a8992e534dedac7",
            "bcbaa7d759014719912791ddef15c3c2",
            "7721fc4529164782b1a10406a899c178",
            "390ed45884b9478d829ab98fb5b5a1e5",
            "b81df7e67a044e9b89fc2f962aeb471f",
            "ac980bbeabfb42f9b167ae6f6841d8e3",
            "bce3290bf98f4252b77e9ade697cbce4",
            "693c99d508e04f7787fe1c832f1cfc00",
            "af4125056ef04fce967a747368e17f0a",
            "d4a9692e84344b7fbb0980b89723a4c0",
            "0e54809a18c64b6eb50b0b4628db42aa",
            "853973605bae4ec4b84c63497490c8b3",
            "d8a56f7a5162498d9927d3668482b67b",
            "bbb539bfbad7443a9438010f684b5b10",
            "1762083d5e704eac8c65d0f0528c521e",
            "251100edbafd41ab955d8f620e3fcde5",
            "d85b07122eba41c9adbf7f33ed15beef",
            "8ed994e468c941debd9864228a27ddb8",
            "f2142f066509457d80c0fd851daa1e54",
            "7ccdd7a85645462c953ef41de0f7ac56",
            "e9a10bf9695e4cf798c55efc480bc447",
            "41cd94f4ab09476bb6c16b8fdb14f399",
            "76c43c78d9a54518937b7b92a164d8b8",
            "744a3f4648ee4acaaff729af93e2f86e",
            "4d260760b69f4a4f97173169fe505c67",
            "8871f76faf9f442b8730b260bce4dbd1",
            "34a0d90d197a49b4881821cf30968d60",
            "65c0ffe932ca4f25899f52eeb897be70",
            "17609ecfa19d43ecb4e51536ee169c39",
            "cc94ff6990a14597aefdf0b17c703647",
            "d7e6e744bb884e81876a39ac8b35b479",
            "c203298342cc4704a60ba687eb3e70c5",
            "adaf2117ce294337bd4001145cac89c5",
            "2d9faf9266264e0487b0db3d8f09d09c",
            "3e36bb4f3f954231bb00e69a8240c9cf",
            "eed845a350cc4ced810f11b9555cd1ab",
            "c47e79cc7da84957910738e27f0ee805",
            "97a950da39904ddeb2f988360e03ca81",
            "cc6fa6310a7e46d1b61dc4e88214edec",
            "818117ad1e914abdab03e02e0663fa86",
            "d409416f4bf649839501f1c853d30415",
            "6cf837dca646422eb5ec44033a1e1dff",
            "61ad00be04cb4b24bbb183816a72dd0b",
            "2b0787c5d71c40cc94f9dce240e233f5",
            "1713ba941ddd4f0eb1e0a323cab90dc2",
            "a3d641af2a5d4ffa86d6b1956c91a63a",
            "29b617b6f2fd45f0a397f943d4471680",
            "821d5215bf3d4bf2b49dbcabfe826b39",
            "05320863dbbd4d7980f5f3bd82de5b6b",
            "90cb57eea72b4b539fb93395039725b6",
            "b2a2bc5a46f74671b5cd3d53518555a5",
            "4aa1ad307ad04f37b3f26e9110617233",
            "99c2213da6d9406a8f72db765b45c8bb",
            "f31aa1c9b45d42cdad17a35008d83246",
            "97b58072a4b442beb42df64987ed16db",
            "c05dc976797a4cbe82e3c7c982b8f26a",
            "83d229f50e784c21b4a2b4fd7fc9c45a",
            "e4a82c5146fb4e469610fd238f490689",
            "5b979d1960d242baa246e4e54580b3c5",
            "c2eb113b70bf443280afed3f6bba7c2f",
            "c0f05ab3e869449b975aa32d34994340",
            "0a5a6811cda2495785f6a0c7f68d9799",
            "83dab553949c43e4a9dd580d7c63fa37",
            "58d0d67787364e1c9f8fbbe70bdc5188"
          ]
        },
        "id": "u3MvCcmHsY5z",
        "outputId": "49256291-28cc-4b05-b6c7-af78fcf871a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3.4\n",
            "Initializing drivers ... WS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/853 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e0d2a0eef604c9e8b3b90f53110aeb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/39.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fda7d38cf87947b68c6497d33966d94e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a71551ac04443b08fcd5836cfb21da5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6bc701fd35b418db36217f0eb97dc60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af1caa9e460f46dfac53678a4d8f6942"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing drivers ... POS\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.91k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc129c35956b440d82684fe311fc9860"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/40.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "262ed90f2f1f414b9363ca67fce55260"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffb7451b161c4a3eb72b6d7085e5b4e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b91452374c384076943cb89d62789d15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28c71bb15a41456b89e08e85cdf78bfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing drivers ... NER\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/3.76k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4a9692e84344b7fbb0980b89723a4c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/40.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9a10bf9695e4cf798c55efc480bc447"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c203298342cc4704a60ba687eb3e70c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61ad00be04cb4b24bbb183816a72dd0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f31aa1c9b45d42cdad17a35008d83246"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing drivers ... all done\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload() #上傳資料\n",
        "# Get the filename from the uploaded dictionary\n",
        "filename = list(uploaded.keys())[0]\n",
        "data = pd.read_csv(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Vg41fblPsHD6",
        "outputId": "0f5f3544-bcb3-4bc0-c8bf-f58c60fa8abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f09e3cd5-538d-4e86-b4c2-d5cabf64badd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f09e3cd5-538d-4e86-b4c2-d5cabf64badd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PSFD_部分_nox01.csv to PSFD_部分_nox01 (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#確認是否有亂碼\n",
        "with open(filename, \"rb\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        try:\n",
        "            line.decode(\"utf-8\")\n",
        "        except UnicodeDecodeError as e:\n",
        "            print(f\"錯誤發生在第 {i+1} 行，錯誤訊息: {e}\")\n",
        "            break\n",
        "print(data.dtypes)\n",
        "print(data.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbNr2gIasd8L",
        "outputId": "00310a7e-9811-4283-bf6d-615f750ec084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mainid      float64\n",
            "lastname     object\n",
            "dtype: object\n",
            "   mainid  lastname\n",
            "0     4.0      應用外語\n",
            "1     3.0  產品與媒體設計系\n",
            "2     6.0        國貿\n",
            "3    17.0     餐飲管理系\n",
            "4     4.0       英文系\n",
            "5     6.0     財務金融系\n",
            "6    10.0       藥學系\n",
            "7    12.0      資訊工程\n",
            "8    12.0     土木工程系\n",
            "9     6.0      財務金融\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(subset=['mainid'], inplace=True)\n",
        "data['mainid'] = data['mainid'].astype(int)"
      ],
      "metadata": {
        "id": "9zNdfbXLQBmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 儲存分詞結果與新的句子\n",
        "data[\"result\"] = \"\"\n",
        "data[\"n_lastname\"] = \"\"\n",
        "\n",
        "# 進行每個部份的分析\n",
        "for index, row in data.iterrows():\n",
        "    description = row[\"lastname\"]\n",
        "    # 分詞\n",
        "    ws_result = ws_driver([description])\n",
        "    # 詞性標註\n",
        "    pos_result = pos_driver(ws_result)\n",
        "\n",
        "    # 清洗數據\n",
        "    cleaned_sentence, cleaned_with_pos = clean(ws_result[0], pos_result[0])\n",
        "\n",
        "    # 保存结果\n",
        "    data.at[index, \"result\"] = cleaned_with_pos\n",
        "    data.at[index, \"n_lastname\"] = cleaned_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn3RXLPNsi-N",
        "outputId": "1a64ecc2-8e52-4b7c-90d6-94593bac86d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5753.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5315.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5041.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5440.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5178.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5210.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4744.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6260.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6150.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5801.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5077.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5511.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6132.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4228.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5482.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5497.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4036.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5249.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4044.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5391.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5652.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5475.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4198.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5356.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5398.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5059.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5833.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6492.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5249.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5115.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5857.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5966.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5210.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5242.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1098.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1565.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4963.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5322.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5540.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5533.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5197.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4882.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4940.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5637.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4588.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5236.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5127.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5165.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4619.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4401.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3741.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5447.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4529.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5761.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6043.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4963.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5533.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6297.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6177.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6260.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6052.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4771.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5391.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3912.60it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5482.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1934.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4593.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5322.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5667.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5866.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5548.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5475.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5562.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4843.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 354.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4359.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5152.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4928.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6278.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6384.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6150.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5269.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5915.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6213.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5907.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5391.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5637.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5165.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3041.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5363.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6260.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5966.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5377.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5540.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4843.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4190.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5974.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5108.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4975.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5184.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5384.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6423.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4894.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5652.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4429.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4894.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4946.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6563.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5737.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6061.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2995.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5398.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5533.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5540.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4755.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5482.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6232.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5949.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5857.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6078.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5932.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5899.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6159.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4946.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5190.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5966.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5309.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5242.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 768.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5761.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4332.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2563.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5866.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4928.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4832.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5356.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4894.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4466.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4922.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4798.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6241.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4249.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5497.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6326.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5511.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5184.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4739.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5482.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5071.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5384.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3141.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5140.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4777.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4993.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5801.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4899.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5419.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 842.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5108.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3650.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5940.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4691.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4524.60it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6043.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5121.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5577.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5667.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4911.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6462.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3971.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5899.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2014.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5841.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4993.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5957.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6288.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6132.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5017.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6615.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5761.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5029.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6978.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5629.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4771.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5096.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5899.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6159.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5315.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6297.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6364.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5282.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5203.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5398.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5146.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5785.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4702.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4905.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2651.27it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6132.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5363.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5242.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6533.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4975.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6269.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4798.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4391.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5548.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4782.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5652.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4092.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5841.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4271.19it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2713.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5785.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6605.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5447.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2943.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5041.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4755.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3823.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2570.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4832.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5269.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6105.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4644.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5223.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5197.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 813.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4707.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1583.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5165.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4604.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5309.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5295.84it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5370.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4860.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5866.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6432.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4660.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4957.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5562.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5377.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6543.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5256.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6326.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6052.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 764.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5152.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5356.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5133.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5171.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3307.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2037.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5084.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5121.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5210.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3894.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4905.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5440.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5761.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4987.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6393.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5108.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5825.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5329.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4911.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5165.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5391.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5769.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5289.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5041.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5023.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2334.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5302.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5940.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5974.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5203.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5242.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5053.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5652.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5329.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5482.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5761.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4911.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4865.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4378.19it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4681.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5084.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5482.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5041.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 926.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5236.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4634.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4723.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4401.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4723.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5629.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5140.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4993.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4723.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5419.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4539.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5133.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5315.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5343.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5275.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5309.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5309.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4346.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4871.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4940.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5077.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5329.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6335.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4826.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3647.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4750.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6853.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5282.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5966.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5184.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4660.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5440.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6105.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6087.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4888.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5825.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5108.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5197.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6492.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6177.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4655.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4848.91it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5737.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5447.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5289.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5475.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1800.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6232.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3331.46it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6123.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4969.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3765.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6078.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4882.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5548.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1766.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5140.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5289.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4634.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5275.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5269.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5090.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5940.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6078.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5924.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5899.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2632.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5667.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5289.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6297.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5127.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6533.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4975.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4599.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5637.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5384.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5833.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5562.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5190.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5924.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5570.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5178.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4957.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6043.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5269.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5223.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5391.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4387.35it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4848.91it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4554.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4629.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5377.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4793.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5140.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5302.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4485.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4718.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5090.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5932.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5315.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6078.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5548.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5801.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4660.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4599.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5412.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5761.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3566.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4798.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2348.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5475.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4644.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5614.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6087.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5577.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6087.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6159.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6150.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5041.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2532.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5475.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5377.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6678.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5570.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4660.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4301.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5398.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5343.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5090.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4529.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4928.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4202.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5737.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6297.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6743.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5216.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5071.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5753.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5841.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5540.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3628.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4788.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5667.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5178.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4723.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5866.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4297.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5256.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4076.10it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5932.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5127.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4438.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3021.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5412.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4750.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5065.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4793.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4544.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4563.99it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5210.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5108.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5203.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5753.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5349.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5533.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5315.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5825.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5152.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5419.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5777.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6052.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5629.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6288.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1624.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4854.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5504.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1644.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5184.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5482.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5447.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5949.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4718.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4433.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3792.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5482.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5077.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6307.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5577.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5899.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6278.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6260.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6553.60it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5370.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5577.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5152.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5907.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4940.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3204.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 858.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6159.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6078.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5029.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6232.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5924.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5315.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4707.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5391.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5102.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5841.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5652.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5447.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4843.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5817.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5023.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4702.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4987.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3446.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4481.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5497.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5785.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5533.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5329.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4249.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5857.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6260.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5482.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5949.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5899.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3163.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3883.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5825.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5652.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3640.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3006.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6269.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5570.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6502.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5562.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5924.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4447.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4798.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5570.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 235.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3068.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5562.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6009.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4573.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4240.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5504.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5343.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5249.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5295.84it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4999.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4993.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5932.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5005.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5548.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6105.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5825.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5737.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6105.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4871.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3865.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4771.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6232.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5841.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6543.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4975.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6213.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5282.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5391.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3731.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5363.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5940.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5737.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5949.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5753.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4245.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5915.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5440.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5384.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5785.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1378.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3979.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5801.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5753.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4848.91it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5295.84it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4319.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 686.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4116.10it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4529.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4476.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4782.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6009.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5349.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5349.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5275.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5178.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5504.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5562.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5343.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5614.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4495.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5475.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3179.91it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5801.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5343.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5184.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6105.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5336.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5309.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5957.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3983.19it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 992.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6123.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4882.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5203.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5336.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6326.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6105.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6009.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5152.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3279.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4917.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3876.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4993.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5511.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4655.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5029.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5071.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6009.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5356.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5440.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6150.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5949.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4940.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5737.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6452.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5637.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6442.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5899.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6384.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6335.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6831.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5833.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6132.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6721.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4559.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5562.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3983.19it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6921.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5077.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1399.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4108.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5282.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6132.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4882.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5322.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5548.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5785.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4064.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6241.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5210.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5645.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5907.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3826.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5171.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5761.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5242.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5289.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5053.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5216.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4739.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5190.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7206.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5029.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5737.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5957.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5570.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5005.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5761.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6241.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5295.84it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5440.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4021.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5614.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5825.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6482.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5966.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2255.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5974.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5236.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5777.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6842.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4888.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6442.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5363.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6502.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5329.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6052.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5833.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5940.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7025.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5343.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6150.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6326.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5540.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4253.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6512.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4894.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5932.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4288.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5377.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5419.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5924.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6052.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4462.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5249.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6288.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5966.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4723.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5949.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4957.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6241.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3698.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4080.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5127.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5011.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5053.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2743.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6326.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5957.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6087.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5121.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5322.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5785.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4755.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5454.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5349.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5769.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6335.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6078.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 343.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5249.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 681.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5216.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5833.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4529.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6043.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1068.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5011.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4681.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2087.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6482.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5178.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5577.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6009.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5454.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4593.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5833.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5562.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6482.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4728.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5011.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5210.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2131.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6177.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5857.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5932.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5077.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5440.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5629.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6061.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5005.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6326.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5637.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5275.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6647.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6678.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4788.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5548.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5769.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5907.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5570.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3231.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6278.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6241.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4993.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4355.46it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4466.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5275.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5652.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5907.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5171.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5866.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5899.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6052.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5059.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6288.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5637.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6472.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3506.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4739.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7256.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5419.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6442.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5857.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 654.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6374.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6213.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6335.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5548.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5223.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5322.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5915.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6875.91it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3659.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5059.47it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5349.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4301.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5029.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5127.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5966.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6393.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4934.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5005.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5540.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5140.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3919.91it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6260.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5077.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3647.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5817.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5391.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5637.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6297.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6307.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5447.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5302.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5753.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6786.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5504.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5777.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5753.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5140.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5398.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6364.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3685.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5447.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5866.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5065.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5737.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6123.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5029.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5203.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6269.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5577.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1081.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5256.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5924.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5915.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6765.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6978.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6732.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6543.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4675.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5370.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5041.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5322.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2202.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6078.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4771.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4387.35it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5041.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5857.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5637.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5309.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5614.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5667.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5047.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5178.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5761.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5454.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5915.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5629.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5289.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2559.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5841.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 384.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5737.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6721.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4084.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5533.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5454.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6442.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5090.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5302.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7025.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5667.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6123.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5825.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5924.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5356.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4495.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5336.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4877.10it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5753.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6543.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4410.41it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4905.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4882.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6574.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6374.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4899.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4981.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5011.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6594.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5171.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5504.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5349.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6423.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4854.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4877.10it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5769.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4882.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4771.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5071.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5289.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5511.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5197.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5660.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5275.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4871.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4563.99it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6393.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6177.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6452.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5309.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6213.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5370.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6278.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5652.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6944.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5645.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6078.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5115.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4655.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5419.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 699.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6364.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5769.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5349.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5793.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5932.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5899.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6584.46it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5577.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6523.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5785.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5504.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5957.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5833.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5475.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6523.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6335.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1048.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5256.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1681.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6472.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5629.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6069.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5652.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6150.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7598.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7384.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6898.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7489.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7049.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8208.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5295.84it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6442.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8035.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6955.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6269.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5915.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7612.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8160.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6743.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7913.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8322.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8256.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5115.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7973.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5140.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7096.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7612.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3971.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8665.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7423.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8035.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8371.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8208.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7667.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7049.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4712.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7206.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7570.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6482.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7724.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7345.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7108.99it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6978.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7281.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8490.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8192.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6061.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7096.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7653.84it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6754.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5974.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5454.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6743.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6553.60it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8240.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8004.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7781.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6875.91it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7384.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7913.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6034.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5667.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8405.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6297.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8630.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8097.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7898.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7133.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7281.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7989.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8848.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7516.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6553.60it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7710.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6786.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7612.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4634.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6820.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7598.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7489.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6132.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6797.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6553.60it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6307.22it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7898.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7476.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8272.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7133.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5890.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7781.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6853.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4882.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4665.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7269.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7667.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8240.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5242.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6700.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6944.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5974.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5645.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7653.84it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7145.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6442.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6563.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7710.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6462.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7049.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6326.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6743.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6842.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7157.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7206.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5866.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7584.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7810.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7898.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7145.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6482.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6260.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6978.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6808.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6543.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7332.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7182.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7557.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6990.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7767.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7397.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7825.19it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5343.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7463.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2257.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5540.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7002.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8176.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7898.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6626.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5349.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7516.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7913.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6875.91it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7681.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8322.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7913.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8272.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4529.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8305.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8144.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7667.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8289.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7157.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4253.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 272.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8004.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6955.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6955.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8144.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5440.08it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6355.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3258.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7307.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7530.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6278.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6921.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6177.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5974.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7598.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8176.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7049.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7307.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6967.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7133.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6574.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7157.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7667.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7958.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8542.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7073.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6820.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6853.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7463.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7061.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7397.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8542.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7767.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6657.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6442.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7244.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7489.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6820.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7133.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8160.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6584.46it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7781.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8456.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4447.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7332.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7781.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7724.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7182.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6647.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7332.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7108.99it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7854.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8405.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8577.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7928.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7557.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4104.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6678.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7463.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6657.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6678.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5957.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7002.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6533.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8035.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7570.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6364.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7061.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4660.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6808.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6615.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8422.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8701.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6732.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6213.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7345.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 10131.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6472.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7530.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7898.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7612.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7219.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7463.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8097.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7269.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7681.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 9157.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6797.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6967.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7182.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8525.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7612.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7928.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7157.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7371.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6944.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7244.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7557.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8405.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6087.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5841.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6150.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7423.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8756.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7598.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6754.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7869.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7667.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6944.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2498.10it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8224.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6384.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7244.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7489.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6754.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7570.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8322.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6765.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6543.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4424.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5915.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7796.10it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6563.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7557.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7854.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7281.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7898.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3711.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7667.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6584.46it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8456.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8256.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5866.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7096.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6105.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3284.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7854.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8112.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8355.19it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6955.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1742.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2394.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7530.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7319.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6364.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6269.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7002.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5645.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1260.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6232.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7345.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7463.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6668.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7256.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7073.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7913.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6898.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7371.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6626.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6797.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2246.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6864.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6492.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2375.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2296.99it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8081.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8097.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6533.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6574.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6159.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6594.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8719.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7612.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8490.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7384.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7476.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7269.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6647.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8594.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5801.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6288.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6647.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8630.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6150.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6636.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8338.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8305.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6278.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7570.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7913.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7269.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6944.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7710.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7449.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6584.46it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6944.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6563.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6374.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5866.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7973.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6944.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6123.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6326.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8004.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7244.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7530.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5777.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8719.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6452.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6123.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6472.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8050.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7061.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6423.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7206.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8322.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7108.99it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6955.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6374.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2263.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4108.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7073.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6452.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7182.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6523.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6482.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6743.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5540.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6584.46it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6898.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6765.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7133.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6232.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5511.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6932.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6921.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6700.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6647.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6213.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6721.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5966.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1427.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5874.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6657.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6278.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6808.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6364.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7332.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5801.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6842.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6831.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4429.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7598.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7489.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6403.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5017.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7108.99it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5023.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5315.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6657.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7371.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7206.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7463.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6061.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6078.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8422.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7724.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7738.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6853.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7269.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6657.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6721.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7397.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7598.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6345.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8144.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6492.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6978.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8738.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7423.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6668.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6241.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 454.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7145.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6269.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6432.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7157.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 9776.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6864.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4424.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7423.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8338.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8208.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7516.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6472.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5614.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6061.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5171.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6364.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6967.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6626.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8019.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6831.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7345.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7219.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7653.84it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7825.19it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3644.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 725.91it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7219.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6061.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7319.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7653.84it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7557.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 635.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7410.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8322.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8924.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 971.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6605.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7681.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6512.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5915.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3775.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6765.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6384.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6533.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8160.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6898.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7557.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8924.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7958.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7958.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6563.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7767.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7489.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6260.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6423.13it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8388.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8112.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7319.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4262.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7025.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6543.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 2741.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 9039.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6820.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8612.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7989.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6978.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6668.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6533.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6403.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6374.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7724.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6177.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6657.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7319.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6842.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7530.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8507.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8525.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8208.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8019.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 9000.65it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6842.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5127.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5915.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7598.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6955.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6967.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6647.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7397.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7108.99it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6553.60it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4987.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5533.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6069.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7958.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8208.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7516.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6605.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6374.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7584.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8338.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7145.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8004.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6700.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7371.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7825.19it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8004.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8756.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6944.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7796.10it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5562.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7073.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6584.46it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4578.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7073.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7612.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7049.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6853.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8081.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4999.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4206.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6374.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5178.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5454.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4940.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7869.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6269.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8830.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6278.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8240.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5777.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7281.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7096.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6657.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6462.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1206.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6978.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6403.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7781.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8240.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8035.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7796.10it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7157.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8338.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8924.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8594.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6297.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6159.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5447.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7025.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7913.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7049.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7219.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7570.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7244.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6523.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6754.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8050.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6563.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6452.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5957.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6978.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4744.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6594.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7206.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8272.79it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6452.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6502.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7724.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7256.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7854.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6678.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8305.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 10459.61it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7269.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6553.60it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5023.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 9467.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7570.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7281.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8144.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6432.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4341.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6955.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6594.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6393.76it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6797.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5857.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5691.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7269.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7869.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8004.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7854.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6808.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7096.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7489.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6482.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6797.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3979.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6186.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5801.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7397.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6668.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7108.99it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5857.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7332.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5667.98it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7219.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6177.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7061.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7025.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8035.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8719.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6132.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6700.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5932.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6114.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6512.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8112.77it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4718.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6563.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6978.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6853.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8422.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7781.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7449.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7073.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8559.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8050.49it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8192.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8208.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7332.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7002.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 9341.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6921.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7476.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7973.96it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7516.67it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7612.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6636.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6384.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6605.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6732.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7570.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6898.53it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7169.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7989.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8756.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7256.58it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7371.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8830.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8422.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8774.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7463.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6241.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7738.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6462.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8405.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7332.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6177.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8559.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6492.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6626.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7281.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7157.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8256.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4092.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4578.93it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6472.69it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8176.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7958.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8144.28it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6732.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5857.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6842.26it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7384.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7767.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6523.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6543.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7307.15it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7570.95it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7781.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6512.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7025.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7281.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7869.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6668.21it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6605.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7397.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7244.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6087.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6563.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7854.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7206.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7738.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6820.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6132.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6512.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6657.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6932.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7724.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6636.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7206.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7073.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 9822.73it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7681.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6831.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7913.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6204.59it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7869.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8097.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7557.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6563.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7653.84it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7557.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7061.12it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6213.78it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5184.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6820.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6657.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6523.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6721.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5924.16it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6159.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7049.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8665.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6502.80it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7530.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5645.09it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7898.88it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6732.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6831.11it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7025.63it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7869.24it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6403.52it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7332.70it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7371.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5629.94it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6195.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6159.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7397.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8355.19it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6626.07it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7810.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3826.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8665.92it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7767.23it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7319.90it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5769.33it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5309.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5165.40it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4905.62it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6288.31it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6374.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6990.51it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6732.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3622.02it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8322.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7002.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4940.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6297.75it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6594.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7584.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7384.34it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6533.18it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7145.32it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5146.39it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5159.05it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5309.25it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7476.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7397.36it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7423.55it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7530.17it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6594.82it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5614.86it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6678.83it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7584.64it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 8128.50it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6150.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 3698.68it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.93it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4644.85it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 779.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7182.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6921.29it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 7598.38it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 4549.14it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 6150.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s]\n",
            "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 9341.43it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['jeiba_lastname'] = data['lastname'].apply(jieba_text)\n",
        "data['n_lastname'] = data['n_lastname'].fillna(data['jeiba_lastname'])\n",
        "'''\n",
        "nan_indices = data[data['n_lastname'].isna()].index\n",
        "print(nan_indices)\n",
        "nan_rows_details = data.loc[[425, 2172]]\n",
        "print(nan_rows_details)\n",
        "\n",
        "不分系 跟基督教學系會被nan\n",
        "\n",
        "'''\n",
        "print(data.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPF0KlsHvXHr",
        "outputId": "8dc2fa18-157e-4aa9-8883-bc648ce96426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   mainid  midid  lastid\\t   lastname     eduid                        result  \\\n",
            "0       2    201     20101       教育學系  140101.0                 教育(Na) 學系(Na)   \n",
            "1       2    201     20102     比較教育學系  140102.0          比較(VC) 教育(Na) 學系(Na)   \n",
            "2       2    201     20103     國民教育學系  140103.0               國民教育(Na) 學系(Na)   \n",
            "3       2    201     20104   多元文化教育學系  140104.0   多元(VH) 文化(Na) 教育(Na) 學系(Na)   \n",
            "4       2    201     20105   課程與教學研究所  140105.0         課程(Na) 教學(VA) 研究所(Nc)   \n",
            "5       2    201     20105      課程研究所  140105.0                課程(Na) 研究所(Nc)   \n",
            "6       2    201     20106  教育專業發展研究所  140106.0  教育(Na) 專業(VH) 發展(Na) 研究所(Nc)   \n",
            "7       2    201     20107  教育心理與輔導學系  140107.0        教育(Na) 心理(Na) 輔導學系(Na)   \n",
            "8       2    201     20107       輔導學系  140107.0                      輔導學系(Nc)   \n",
            "9       2    201     20108  教育心理與諮商學系  140108.0   教育(Na) 心理(Na) 諮商(VE) 學系(Na)   \n",
            "\n",
            "     n_lastname jeiba_lastname  \n",
            "0         教育 學系          教育 學系  \n",
            "1      比較 教育 學系       比較 教育 學系  \n",
            "2       國民教育 學系       國民 教育 學系  \n",
            "3   多元 文化 教育 學系     多元 文化教育 學系  \n",
            "4     課程 教學 研究所    課程 與 教學 研究所  \n",
            "5        課程 研究所         課程 研究所  \n",
            "6  教育 專業 發展 研究所   教育 專業 發展 研究所  \n",
            "7    教育 心理 輔導學系  教育 心理 與 輔導 學系  \n",
            "8          輔導學系          輔導 學系  \n",
            "9   教育 心理 諮商 學系  教育 心理 與 諮 商學系  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nan_indices = data[data['n_lastname'].isna()].index\n",
        "print(nan_indices)\n",
        "nan_rows_details = data.loc[[425, 2172]]\n",
        "nan_rows_details"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "I0kBOB3-2yeD",
        "outputId": "764a88a0-3385-4821-f341-ccaa13d66ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index([], dtype='int64')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      mainid  midid  lastid\\t lastname     eduid result n_lastname  \\\n",
              "425        4    408     40805    基督教學系  220805.0    NaN     基督教 學系   \n",
              "2172      97   9703    970303      不分系  990199.0    NaN        不分系   \n",
              "\n",
              "     jeiba_lastname  \n",
              "425          基督教 學系  \n",
              "2172            不分系  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1544742-0d09-48f2-a4fc-5c0bbf2f7ddb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mainid</th>\n",
              "      <th>midid</th>\n",
              "      <th>lastid\\t</th>\n",
              "      <th>lastname</th>\n",
              "      <th>eduid</th>\n",
              "      <th>result</th>\n",
              "      <th>n_lastname</th>\n",
              "      <th>jeiba_lastname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>4</td>\n",
              "      <td>408</td>\n",
              "      <td>40805</td>\n",
              "      <td>基督教學系</td>\n",
              "      <td>220805.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>基督教 學系</td>\n",
              "      <td>基督教 學系</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2172</th>\n",
              "      <td>97</td>\n",
              "      <td>9703</td>\n",
              "      <td>970303</td>\n",
              "      <td>不分系</td>\n",
              "      <td>990199.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>不分系</td>\n",
              "      <td>不分系</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1544742-0d09-48f2-a4fc-5c0bbf2f7ddb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1544742-0d09-48f2-a4fc-5c0bbf2f7ddb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1544742-0d09-48f2-a4fc-5c0bbf2f7ddb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-93cda9b6-eb2f-45c5-874f-ee63420b00be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93cda9b6-eb2f-45c5-874f-ee63420b00be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-93cda9b6-eb2f-45c5-874f-ee63420b00be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ae74fb2e-14e3-4484-aa5d-07ed37190ee0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('nan_rows_details')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ae74fb2e-14e3-4484-aa5d-07ed37190ee0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('nan_rows_details');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "nan_rows_details",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_filename = \"2022科系分類_奕嘉_已經分詞.csv\"\n",
        "data.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "c-46RxgZ20oj",
        "outputId": "4382013f-9ec7-401e-8916-ae735c111d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_33bd243a-33f6-4fb6-ad59-43d800e680e2\", \"2022\\u79d1\\u7cfb\\u5206\\u985e_\\u5955\\u5609_\\u5df2\\u7d93\\u5206\\u8a5e.csv\", 302660)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##分類測試"
      ],
      "metadata": {
        "id": "6bRd98heWct0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 隨機森林"
      ],
      "metadata": {
        "id": "3p4tIEe20euj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import jieba\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from google.colab import files\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n"
      ],
      "metadata": {
        "id": "hXGnYSzp00TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload() #上傳資料\n",
        "# Get the filename from the uploaded dictionary\n",
        "filename = list(uploaded.keys())[0]\n",
        "data = pd.read_csv(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "m-HAQnJN0gub",
        "outputId": "f81dbdc7-69a3-47a4-c691-7334fdfc9ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9b552b27-5bc2-4c7c-923b-06d114d22f4d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9b552b27-5bc2-4c7c-923b-06d114d22f4d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 科系分類_奕嘉_已經分詞.csv to 科系分類_奕嘉_已經分詞 (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nan_indices = data[data['n_lastname'].isna()].index\n",
        "print(nan_indices)\n",
        "nan_rows_details = data.loc[[425, 2172]]\n",
        "print(nan_rows_details)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wKcGmec1_a8",
        "outputId": "98224bbe-9ac6-4a23-f514-f517dea8360d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index([], dtype='int64')\n",
            "      mainid  midid  lastid\\t lastname     eduid result n_lastname  \\\n",
            "425        4    408     40805    基督教學系  220805.0    NaN     基督教 學系   \n",
            "2172      97   9703    970303      不分系  990199.0    NaN        不分系   \n",
            "\n",
            "     jeiba_lastname  \n",
            "425          基督教 學系  \n",
            "2172            不分系  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nan_rows_details = data.loc[[425, 2172]]\n",
        "print(nan_rows_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7u-6cs42cUz",
        "outputId": "2c707c71-1641-46a4-ac10-48a7b14cf88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      mainid  midid  lastid\\t lastname     eduid result n_lastname  \\\n",
            "425        4    408     40805    基督教學系  220805.0    NaN     基督教 學系   \n",
            "2172      97   9703    970303      不分系  990199.0    NaN        不分系   \n",
            "\n",
            "     jeiba_lastname  \n",
            "425          基督教 學系  \n",
            "2172            不分系  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徵向量化，使用 Tfidf 向量化\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(data['n_lastname'])\n",
        "\n",
        "# 職業編號當作目標變量\n",
        "y = data['mainid']\n",
        "\n",
        "# 分割數據為訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "# 訓練模型\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 預測和評估\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t__KtJeB0jC0",
        "outputId": "2848ad92-b788-4145-fbb3-5778e897a403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.97      0.89      0.93        35\n",
            "           3       0.78      0.91      0.84        34\n",
            "           4       0.45      0.52      0.48        27\n",
            "           5       0.51      0.79      0.62        43\n",
            "           6       0.70      0.76      0.73        50\n",
            "           7       0.80      0.80      0.80         5\n",
            "           8       0.68      0.60      0.64        25\n",
            "           9       1.00      0.47      0.64        17\n",
            "          10       0.74      0.70      0.72        33\n",
            "          11       1.00      0.29      0.44         7\n",
            "          12       0.76      0.86      0.81        71\n",
            "          13       1.00      0.55      0.71        11\n",
            "          14       0.73      0.40      0.52        20\n",
            "          15       0.50      0.25      0.33         8\n",
            "          16       0.88      0.54      0.67        13\n",
            "          17       0.81      0.81      0.81        27\n",
            "          18       0.78      0.78      0.78         9\n",
            "          97       1.00      0.60      0.75         5\n",
            "\n",
            "    accuracy                           0.72       440\n",
            "   macro avg       0.78      0.64      0.68       440\n",
            "weighted avg       0.75      0.72      0.71       440\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#準確率不高，所以採用smote 後再進行\n",
        "\n",
        "# 檢查類別分部\n",
        "data_df = pd.DataFrame({'lastname': data['n_lastname'], 'label': data['mainid']})\n",
        "label_counts = data_df['label'].value_counts()\n",
        "\n",
        "# 查看是否有少於5筆的樣本\n",
        "rare_labels = label_counts[label_counts < 6].index\n",
        "print(f\"稀有類別: {rare_labels}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk6y50kB6J27",
        "outputId": "48954eaa-e37b-4094-f00e-7bf81e3cbbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "稀有類別: Index([], dtype='int64', name='label')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 處理不均衡數據 (使用 SMOTE)\n",
        "X = data_df['lastname'].tolist()\n",
        "y = data_df['label'].tolist()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# 將文本數據轉換為數值特徵\n",
        "vectorizer = TfidfVectorizer(max_features=2500, min_df=1, max_df=0.9)  # 取前 2000 個高頻詞\n",
        "X_vectorized = vectorizer.fit_transform(X)\n",
        "\n",
        "\n",
        "# 使用 SMOTE 平衡類別分佈\n",
        "smote = SMOTE(sampling_strategy='not minority', random_state=42, k_neighbors=5) #複製not minority\n",
        "X_resampled, y_resampled = smote.fit_resample(X_vectorized, y_encoded)\n",
        "\n",
        "# 分割數據集\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=69, stratify=y_resampled\n",
        ")"
      ],
      "metadata": {
        "id": "HYPAPIRe7Vyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練模型：這裡用訓練特徵和訓練標籤\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(train_texts, train_labels)\n",
        "\n",
        "# 預測和評估：用驗證特徵進行預測，並將預測結果與驗證標籤比較\n",
        "y_pred = model.predict(val_texts)\n",
        "print(classification_report(val_labels, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gGDDKkN8pp0",
        "outputId": "7dd78a4f-9267-4253-f118-42be097219eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97        74\n",
            "           1       0.94      0.89      0.92        74\n",
            "           2       0.96      0.96      0.96        73\n",
            "           3       0.74      0.92      0.82        73\n",
            "           4       0.88      0.86      0.87        74\n",
            "           5       0.99      0.97      0.98        74\n",
            "           6       0.89      0.92      0.91        74\n",
            "           7       0.96      0.96      0.96        74\n",
            "           8       0.94      0.91      0.92        74\n",
            "           9       1.00      0.99      0.99        74\n",
            "          10       0.89      0.78      0.83        74\n",
            "          11       0.92      0.97      0.95        74\n",
            "          12       0.95      0.95      0.95        74\n",
            "          13       0.99      0.97      0.98        74\n",
            "          14       0.97      0.99      0.98        74\n",
            "          15       0.96      0.97      0.97        74\n",
            "          16       0.99      0.99      0.99        74\n",
            "          17       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.94      1259\n",
            "   macro avg       0.94      0.90      0.91      1259\n",
            "weighted avg       0.94      0.94      0.94      1259\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 對答案\n"
      ],
      "metadata": {
        "id": "xr7ck-Ekmrzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload() #上傳資料\n",
        "# Get the filename from the uploaded dictionary\n",
        "filename = list(uploaded.keys())[0]\n",
        "data2 = pd.read_csv(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "DqoQ1RBrmuc1",
        "outputId": "d8763444-7517-4a98-d34e-3c4c1e882710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aa1a94dd-8393-4a07-9b0e-ae9534f8744c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aa1a94dd-8393-4a07-9b0e-ae9534f8744c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PSFD_部分_nox01_已經分詞.csv to PSFD_部分_nox01_已經分詞.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_evaluate(new_data, model):\n",
        "    # 取得預測結果，注意這裡假設模型接受 ln_lastname 欄位作為輸入\n",
        "    # 將文本數據轉換為數值特徵\n",
        "    X_new = vectorizer.transform(new_data['n_lastname'])\n",
        "\n",
        "    predicted_ids = model.predict(X_new)\n",
        "\n",
        "    # 使用相同的 label_encoder 將編碼數字轉回原始標籤\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_ids)\n",
        "\n",
        "    # 將預測結果加入 DataFrame 中\n",
        "    new_data['predicted_label'] = predicted_labels\n",
        "\n",
        "    # 根據預測結果與原始 mainid 進行比較，產生 code 欄位 (1 表示預測正確，0 表示錯誤)\n",
        "    new_data['code'] = (new_data['predicted_label'] == new_data['mainid']).astype(int)\n",
        "\n",
        "    # 計算準確率\n",
        "    accuracy = new_data['code'].mean()\n",
        "    print(\"準確率：\", accuracy)\n",
        "    return new_data, accuracy"
      ],
      "metadata": {
        "id": "2asFTPRoZJsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2, acc = predict_and_evaluate(data, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uS9A0HalBN7",
        "outputId": "800e544f-3d5b-498c-d1dd-965e225a398b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "準確率： 0.9626933575978162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#輸出結果\n",
        "output_filename = \"預測結果比對.csv\"\n",
        "data2.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QCpl1jR4oK5j",
        "outputId": "071b770c-daa1-422f-9f47-b8f57f4b743c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0367cbcf-7908-400b-90b1-63f8f5ce75dc\", \"\\u9810\\u6e2c\\u7d50\\u679c\\u6bd4\\u5c0d.csv\", 317701)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###儲存模型"
      ],
      "metadata": {
        "id": "bJlzzE_vtvXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "# 儲存模型\n",
        "joblib.dump(model, 'model.joblib')\n",
        "joblib.dump(vectorizer, 'vectorizer.joblib')\n",
        "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
        "\n",
        "# 下載模型檔案到本地\n",
        "files.download('model.joblib')\n",
        "files.download('vectorizer.joblib')\n",
        "files.download('label_encoder.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gq15jguWlIuP",
        "outputId": "a8d2a133-1e43-4ab1-c3fd-fda8ca6a7fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fba5d3b9-8f6d-4fd4-ba56-66254058ecff\", \"model.joblib\", 480756649)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e8d09aab-24b4-4c94-bd8b-a418f9173ff6\", \"vectorizer.joblib\", 33543)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e91a4226-4dea-4c39-a600-72bb6a633e95\", \"label_encoder.joblib\", 471)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 上傳模型進行使用"
      ],
      "metadata": {
        "id": "lwj-6zCivJqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# 載入模型\n",
        "model = joblib.load('model.joblib')\n",
        "\n",
        "# 載入 TF-IDF vectorizer\n",
        "vectorizer = joblib.load('vectorizer.joblib')\n",
        "\n",
        "# 載入 LabelEncoder\n",
        "label_encoder = joblib.load('label_encoder.joblib')"
      ],
      "metadata": {
        "id": "O4AiCTBzvfnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote remove origin"
      ],
      "metadata": {
        "id": "TRCIe-CLvjSz",
        "outputId": "19e5504b-f9b2-45e3-eafb-a6f4550d0f29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    }
  ]
}